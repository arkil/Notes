##CentralLimit theorem:

If x_bar is the mean of a random sample X1, X2, ... , Xn of size n from a distribution with a finite mean mu and a finite positive variance sigma ²,
then the distribution of W = (x_bar -mu)/ (sigma/sqrt(n)) is N(0,1) in the limit as n approaches infinity.

This means that the variable is distributed N(mu,sigma/sqrt(n)).

##Binomal Distribution :

With parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question

P(x=k) = (n,k) * p^k * (1 - p)^(n-k)

(n,k) = n! / (k! (n - k)!)

Mu = n*p 
Sigma = n*p*(1-p)

##Type 1 Error ;

Type I error is the rejection of a true null hypothesis (also known as a "false positive" finding)

Type I error is to falsely infer the existence of something that is not there

##Type2 Error

type II error is retaining a false null hypothesis (also known as a "false negative" finding)

a type II error is to falsely infer the absence of something that is

## kolmogrov smirnoff test

Is a nonparametric test of the equality of continuous, one-dimensional probability distributions that can be used to compare a sample with a reference probability distribution (one-sample K–S test), or to compare two samples (two-sample K–S test)

## Bootstrap  

statistical method for estimating the sampling distribution of an estimator by sampling with replacement from the original sample, most often with the purpose of deriving robust estimates of standard errors and confidence intervals of a population parameter like a mean, median, proportion, odds ratio, correlation coefficient or regression coefficient.

## JackKnife 

The jackknife estimator of a parameter is found by systematically leaving out each observation from a dataset and calculating the estimate and then finding the average of these calculations.				

# 
the distribution of the test statistic under the null hypothesis is obtained by calculating all possible values of the test statistic under rearrangements of the labels on the observed data points

# Two tailed test

appropriate if the estimated value may be more than or less than the reference value, for example, whether a test taker may score above or below the historical average

# One Failed test 

appropriate if the estimated value may depart from the reference value in only one direction, whether a machine produces more than one-percent defective products

# Permutation test 

the distribution of the test statistic under the null hypothesis is obtained by calculating all possible values of the test statistic under rearrangements of the labels on the observed data points

# Two way table 

two-way table presents categorical data by counting the number of observations that fall into

# Co relation coefficent 

R = 1/(n-1) * Sum( ((x-x_mean)/std_x ) * ((y-y_mean)/std_y)) )

# Anova

Analysis of variance is a statistical method used to test differences betwwen two or more means of variance 


 